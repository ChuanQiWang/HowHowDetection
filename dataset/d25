用網路建Cluster的好處是性價比高、容易建，每個節點都是單一的電腦，跑一般的作業系統。但唯一的缺點是，節點之間沒有共享的記憶體 (shared memory)。面對這個千古難題 (相對於電腦演進速度而言)，曾經有過所謂的software-based virtual shared memory，也就是以軟體虛擬出節點之間的共享記憶體。但這樣的系統軟體，即便有某種程度的實用性，也曾經商業化，但很容易因為(1)應用上記憶體的存取太過發散，造成效能劣化，(2)軟體在處理網路傳輸協定(例如TCP/IP)時，Latency太高，消耗大量CPU時間，(3)網路塞車或出問題時，容錯處理不容易做好，所以被打入冷宮。以上三個問題，對於傳統HPC和普及(general-purpose)應用來說是不易解的。全世界一年賣出幾套HPC設備? 普及應用不可能找專家來優化程式，所以在那些年代，software-based virtual distributed shared memory (SVDSM)沒辦法蓬勃發展。但當我們從Big Data的角度來看，故事的發展可能會大不同。一開始是雲端，我們有了能夠有了能夠使用大量機器儲存資料、具容錯能力的檔案系統(例如HDFS)，有了能夠輕鬆管控大型Cluster的軟體(例如YARN)，但有人嫌檔案系統太慢，所以做出了能夠使用記憶體存常用資料來做in-memory computation (例如Spark)，接下來又做出使用記憶體來存資料的memory-centric distributed storage system (例如Tachyon)，這一路走來，其實就是讓Cluster在使用者面前，更像一台單一的超多核心、超大記憶體、超大儲存空間、超高網路頻寬的大型共享資源式的電腦主機。雖然Tachyon與SVDSM還有一段不小的距離，但對於Big Data來說，已經很好用了。從Big Data來看問題的好處是，可以忽略傳統應用上最難的那些fine-grain memory access的問題，反正假設資料都是一大塊一大塊的，所以管理資料和metadata的overhead相對低到微不足道，所以上述的問題(1)就不成問題。上述的問題(2)可以用RDMA來解決。現在很多高速網路卡上有RDMA功能，不需要靠CPU來傳輸資料。至於問題(3)，則是靠軟體本身來解決，不靠作業系統，所以我說這類分散式運算的中介軟體，實質上都是作業系統的延伸，也都算是我所謂的系統軟體。關於SVDSM，最近的論文不多，我搜到一篇2014年的論文，裡面沒甚麼研究內容，但作為survey還算可以。A Comparative Analysis of Performance of Shared Memory Cluster Computing Interconnection Systems
